{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 20 News Groups\n",
    "\n",
    "Preprocessing: loading the dataset and vectorizing in word counts (using sickit learn)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.io\n",
    "from sklearn.datasets import fetch_20newsgroups_vectorized\n",
    "from sklearn.utils.validation import check_array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Direct use of fetch_20newsgroups_vectorized\n",
    "\n",
    "The following code is based on the sickit learn test function: scikit-learn/benchmarks/bench_20newsgroups.py\n",
    "\n",
    "See help page for the fetch_20newsgroups_vectorized function [here](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.fetch_20newsgroups_vectorized.html?highlight=fetch_20newsgroups_vectorized)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = fetch_20newsgroups_vectorized(subset=\"train\")\n",
    "data_test = fetch_20newsgroups_vectorized(subset=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check if non-empty 2D array containing only finite values.\n",
    "X_train = check_array(data_train.data, dtype=np.float,\n",
    "                      accept_sparse=\"csc\")\n",
    "X_test = check_array(data_test.data, dtype=np.float, accept_sparse=\"csr\")\n",
    "\n",
    "y_train = data_train.target\n",
    "y_test = data_test.target\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 newsgroups\n",
      "=============\n",
      "X_train.shape = (11314, 130107)\n",
      "X_train.format = csc\n",
      "X_train.dtype = float64\n",
      "X_train density = 0.001214353154362896\n",
      "y_train (11314,)\n",
      "X_test (7532, 130107)\n",
      "X_test.format = csr\n",
      "X_test.dtype = float64\n",
      "y_test (7532,)\n"
     ]
    }
   ],
   "source": [
    "print(\"20 newsgroups\")\n",
    "print(\"=============\")\n",
    "print(\"X_train.shape = {0}\".format(X_train.shape))\n",
    "print(\"X_train.format = {0}\".format(X_train.format))\n",
    "print(\"X_train.dtype = {0}\".format(X_train.dtype))\n",
    "print(\"X_train density = {0}\"\n",
    "      \"\".format(X_train.nnz / np.product(X_train.shape)))\n",
    "print(\"y_train {0}\".format(y_train.shape))\n",
    "print(\"X_test {0}\".format(X_test.shape))\n",
    "print(\"X_test.format = {0}\".format(X_test.format))\n",
    "print(\"X_test.dtype = {0}\".format(X_test.dtype))\n",
    "print(\"y_test {0}\".format(y_test.shape))\n",
    "#print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.19050019, 0.05025189, 0.02277438, ..., 0.08111071, 0.03889549,\n",
       "       0.05679618])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([17,  7, 10, 10,  7,  0, 12, 15,  9,  0, 11,  1,  3,  5,  2,  1,  7,\n",
       "       14,  1, 13,  1, 10, 10, 14,  3,  0, 10,  6, 19,  2])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[:30]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save to MATLAB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "scipy.io.savemat('20newsgroups_train.mat', dict(A=X_train, y=y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## From GAP conf paper (comp.graphics vs. talk.religion.misc TF-IDF)\n",
    "\n",
    "The following code is based on the sickit learn function: scikit-learn/benchmarks/bench_20newsgroups.py\n",
    "\n",
    "It implements the simulation set-up used in the Fercoq et al. 2015 paper \"Mind the duality gap\".\n",
    "\n",
    "See section 4.3. pg. 8:\n",
    "> \"(...) dataset obtained with bag of words features extracted from the 20newsgroup dataset (comp.graphics vs. talk.religion.misc with TF-IDF removing English stop words and words occurring only once or more than 95% of the time). Text feature extraction was done using Scikit-Learn\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 20 news groups\n",
    "#def load_news():\n",
    "data = datasets.fetch_20newsgroups(categories=['comp.graphics',\n",
    "                                               'talk.religion.misc'])\n",
    "vect = TfidfVectorizer(max_df=0.95, min_df=2, stop_words='english') #Vectorizer\n",
    "\n",
    "X = vect.fit_transform(data.data)\n",
    "X = X.astype(np.float)\n",
    "\n",
    "y = data.target.astype(np.float)\n",
    "y[y == 0] = -1.\n",
    "\n",
    "#return X, y\n",
    "\n",
    "# Leukemia\n",
    "# def load_leukemia():\n",
    "#     data = datasets.fetch_mldata('leukemia')\n",
    "#     X = data.data\n",
    "#     y = data.target\n",
    "#     X = X.astype(float)\n",
    "#     y = y.astype(float)\n",
    "#     y /= linalg.norm(y)\n",
    "#     return X, y\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dictionary X is (document vs. word).\n",
    "Input vector y contains the class (+1 or -1 value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 newsgroups\n",
      "=============\n",
      "X.shape = (961, 10094)\n",
      "X.format = csr\n",
      "X.dtype = float64\n",
      "X density = 0.009014019517266107\n",
      "y.shape (961,)\n",
      "y.dtype = float64\n"
     ]
    }
   ],
   "source": [
    "print(\"20 newsgroups\")\n",
    "print(\"=============\")\n",
    "print(\"X.shape = {0}\".format(X.shape))\n",
    "print(\"X.format = {0}\".format(X.format))\n",
    "print(\"X.dtype = {0}\".format(X.dtype))\n",
    "print(\"X density = {0}\"\n",
    "      \"\".format(X.nnz / np.product(X.shape)))\n",
    "print(\"y.shape {0}\".format(y.shape))\n",
    "print(\"y.dtype = {0}\".format(y.dtype))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 2, 1, 1])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save to Matlab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "scipy.io.savemat('20newsgroups_Tfidf.mat', dict(A=X, y=y, words=vect.get_feature_names()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## COUNT DATA : My custom vectorization\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 classes, docs vs. words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = datasets.fetch_20newsgroups(categories=['comp.graphics',\n",
    "                                               'talk.religion.misc'])\n",
    "vect = CountVectorizer(max_df=0.95, min_df=2, stop_words='english')\n",
    "X = vect.fit_transform(data.data)\n",
    "X = X.astype(np.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 newsgroups\n",
      "=============\n",
      "X.shape = (961, 10094)\n",
      "X.format = csr\n",
      "X.dtype = float64\n",
      "X density = 0.009014019517266107\n",
      "y (961,)\n"
     ]
    }
   ],
   "source": [
    "print(\"20 newsgroups\")\n",
    "print(\"=============\")\n",
    "print(\"X.shape = {0}\".format(X.shape))\n",
    "print(\"X.format = {0}\".format(X.format))\n",
    "print(\"X.dtype = {0}\".format(X.dtype))\n",
    "print(\"X density = {0}\"\n",
    "      \"\".format(X.nnz / np.product(X.shape)))\n",
    "print(\"y {0}\".format(y.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. ... 0. 1. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., ..., 2., 1., 1.])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(X.toarray())\n",
    "X.data\n",
    "#print(vect.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save to Matlab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "scipy.io.savemat('20newsgroups_Count_2classes.mat', dict(X=X, words=vect.get_feature_names()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## My custom vectorization (less sparse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 classes, docs vs. words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = datasets.fetch_20newsgroups(categories=['comp.graphics',\n",
    "                                               'talk.religion.misc'])\n",
    "vect = CountVectorizer(max_df=0.95, min_df=5, stop_words='english')\n",
    "X = vect.fit_transform(data.data)\n",
    "X = X.astype(np.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 newsgroups\n",
      "=============\n",
      "X.shape = (961, 4140)\n",
      "X.format = csr\n",
      "X.dtype = float64\n",
      "X density = 0.018039783438145652\n",
      "y (961,)\n"
     ]
    }
   ],
   "source": [
    "print(\"20 newsgroups\")\n",
    "print(\"=============\")\n",
    "print(\"X.shape = {0}\".format(X.shape))\n",
    "print(\"X.format = {0}\".format(X.format))\n",
    "print(\"X.dtype = {0}\".format(X.dtype))\n",
    "print(\"X density = {0}\"\n",
    "      \"\".format(X.nnz / np.product(X.shape)))\n",
    "print(\"y {0}\".format(y.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save to Matlab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scipy.io.savemat('20newsgroups_Count_2classes_reduced.mat', dict(X=X, words=vect.get_feature_names()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All classes, words vs. docs\n",
    "\n",
    "> **THIS IS THE ONE THAT IS USED IN EXPERIMENTS!!!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = datasets.fetch_20newsgroups(subset=\"all\") #(subset=\"all\") to get test and train subsets\n",
    "vect = CountVectorizer(max_df=0.95, min_df=0.054, stop_words='english') #min_df=0.076 for 100 words\n",
    "X = vect.fit_transform(data.data)\n",
    "X = X.astype(np.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 newsgroups\n",
      "=============\n",
      "X.shape = (18846, 204)\n",
      "X.format = csr\n",
      "X.dtype = float64\n",
      "X density = 0.10848455905762495\n",
      "y (961,)\n"
     ]
    }
   ],
   "source": [
    "print(\"20 newsgroups\")\n",
    "print(\"=============\")\n",
    "print(\"X.shape = {0}\".format(X.shape))\n",
    "print(\"X.format = {0}\".format(X.format))\n",
    "print(\"X.dtype = {0}\".format(X.dtype))\n",
    "print(\"X density = {0}\"\n",
    "      \"\".format(X.nnz / np.product(X.shape)))\n",
    "print(\"y {0}\".format(y.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['10', '12', '14', '15', '16', '1993', '20', 'actually', 'article', 'believe', 'best', 'better', 'bit', 'ca', 'case', 'com', 'come', 'computer', 'course', 'cs', 'david', 'day', 'did', 'didn', 'different', 'distribution', 'does', 'doesn', 'don', 'edu', 'end', 'fact', 'far', 'going', 'good', 'got', 'great', 'group', 'help', 'host', 'information', 'just', 'keywords', 'know', 'let', 'like', 'little', 'll', 'long', 'look', 'lot', 'mail', 'make', 'need', 'new', 'news', 'nntp', 'number', 'old', 'people', 'point', 'possible', 'post', 'posting', 'probably', 'problem', 'question', 'read', 'real', 'really', 'reply', 'right', 'said', 'say', 'says', 'science', 'software', 'state', 'sure', 'tell', 'thanks', 'thing', 'things', 'think', 'time', 'true', 'try', 'university', 'usa', 'use', 'used', 'using', 've', 'version', 'want', 'way', 'work', 'world', 'writes', 'year', 'years']\n"
     ]
    }
   ],
   "source": [
    "print(vect.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save to Matlab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "scipy.io.savemat('20newsgroups_Count_100words.mat', dict(X=X, words=vect.get_feature_names()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
